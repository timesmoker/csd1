{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# This is a sample Jupyter Notebook\n",
    "\n",
    "Below is an example of a code cell. \n",
    "Put your cursor into the cell and press Shift+Enter to execute it and select the next one, or click 'Run Cell' button.\n",
    "\n",
    "Press Double Shift to search everywhere for classes, files, tool windows, actions, and settings.\n",
    "\n",
    "To learn more about Jupyter Notebooks in PyCharm, see [help](https://www.jetbrains.com/help/pycharm/ipython-notebook-support.html).\n",
    "For an overview of PyCharm, go to Help -> Learn IDE features or refer to [our documentation](https://www.jetbrains.com/help/pycharm/getting-started.html)."
   ],
   "id": "8a77807f92f26ee"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:07:37.958727Z",
     "start_time": "2024-11-10T14:07:37.267205Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.messages import HumanMessage, SystemMessage,AIMessage\n",
    "from langchain import Tool\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "llm_high = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n"
   ],
   "id": "fbc121e30a2defb3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:07:37.973224Z",
     "start_time": "2024-11-10T14:07:37.970301Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "messages = [\n",
    "        HumanMessage(content=\"Hi! I'm Bob\"),\n",
    "        AIMessage(content=\"Hello Bob! How can I assist you today?\"),\n",
    "        HumanMessage(content=\"What's my name?\"),\n",
    "]\n"
   ],
   "id": "9e2fa557a7d99cda",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-10T14:07:39.028137Z",
     "start_time": "2024-11-10T14:07:38.026163Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain =llm_high|parser\n",
    "chain.invoke(messages)"
   ],
   "id": "badfab66a82fe44f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Bob, based on your introduction.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "\n",
    "# ConversationBufferMemory 초기화\n",
    "memory = ConversationBufferMemory()\n",
    "\n",
    "# LLM Tool 정의: 버퍼 메모리를 사용하여 대화 히스토리를 자동 관리\n",
    "def llm_response_tool_with_buffer(user_input):\n",
    "    # 이전 대화 히스토리를 포함한 메시지 생성\n",
    "    previous_messages = memory.chat_memory.messages\n",
    "    \n",
    "    # 새로운 사용자 메시지 추가\n",
    "    memory.chat_memory.add_message(HumanMessage(content=user_input))\n",
    "    \n",
    "    # LLM 호출하여 응답 생성 (이전 히스토리 포함)\n",
    "    response = llm.invoke(previous_messages + [HumanMessage(content=user_input)])\n",
    "    \n",
    "    # LLM 응답을 메모리에 추가\n",
    "    memory.chat_memory.add_message(AIMessage(content=response.content))\n",
    "    \n",
    "    # 최종 응답 반환\n",
    "    return response.content\n",
    "\n",
    "# Tool 객체 생성\n",
    "llm_tool_with_buffer = Tool(\n",
    "    name=\"LLM Tool with Buffer Memory\",\n",
    "    func=llm_response_tool_with_buffer,\n",
    "    description=\"대화 히스토리를 자동 관리하여 LLM에 응답을 요청하는 도구입니다.\"\n",
    ")\n"
   ],
   "id": "f62e6ca4dd2251a5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain.agents import initialize_agent, AgentType\n",
    "\n",
    "# OpenAI 모델 및 Tool이 포함된 Agent 생성\n",
    "agent = initialize_agent(\n",
    "    tools=[llm_tool_with_buffer],\n",
    "    llm=llm_high,\n",
    "    agent_type=AgentType.CONVERSATIONAL_REACT_DESCRIPTION,\n",
    "    memory=memory  # 대화 메모리를 포함하여 이전 대화 맥락 유지\n",
    ")\n"
   ],
   "id": "2d9b16d6840f949a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from langchain import Tool, OpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "\n",
    "# OpenAI 모델 초기화\n",
    "llm = OpenAI(model=\"gpt-3.5-turbo\")\n",
    "\n",
    "# 1. 분석 Tool 정의: LLM을 사용해 요청 유형을 결정\n",
    "def analyze_with_llm_tool(user_input):\n",
    "    analysis_prompt = (\n",
    "        \"사용자의 요청을 분석하여 필요한 응답의 유형을 결정하세요. \"\n",
    "        \"과거의 사건에 대해 언급하였다면 'recall' \"\n",
    "        \"그렇지 않은 일반 대화라면 'normal', 인식 불가라면 'undefined'를 반환하세요.\\n\\n\"\n",
    "        f\"요청: {user_input}\"\n",
    "    )\n",
    "    \n",
    "    # LLM으로 분석 요청 \n",
    "    analysis_response = llm.invoke([HumanMessage(content=analysis_prompt)])\n",
    "    \n",
    "    # 분석 결과에서 결정된 유형 추출\n",
    "    if \"계산\" in analysis_response.content:\n",
    "        return \"calculator\"\n",
    "    elif \"상담\" in analysis_response.content:\n",
    "        return \"advice\"\n",
    "    else:\n",
    "        return \"unknown\"\n",
    "\n",
    "# Tool 객체 생성\n",
    "analysis_tool = Tool(\n",
    "    name=\"LLM Analysis Tool\",\n",
    "    func=analyze_with_llm_tool,\n",
    "    description=\"요청의 유형을 분석하여 어떤 에이전트를 사용할지 결정합니다.\"\n",
    ")\n",
    "\n",
    "# 2. 관리용 Agent 함수: 분석 Tool을 사용하여 Agent 선택\n",
    "def manage_agents(user_input):\n",
    "    # 분석 Tool을 사용해 요청 유형 결정\n",
    "    agent_type = analysis_tool.func(user_input)\n",
    "    \n",
    "    # 분석 결과에 따라 적절한 Agent 호출\n",
    "    if agent_type == \"calculator\":\n",
    "        response = calculator_agent({\"input\": user_input})[\"output\"]\n",
    "    elif agent_type == \"advice\":\n",
    "        response = advice_agent({\"input\": user_input})[\"output\"]\n",
    "    else:\n",
    "        response = \"죄송합니다, 요청을 처리할 수 없습니다.\"\n",
    "    \n",
    "    return response\n",
    "\n",
    "# 관리용 Agent 실행 예제\n",
    "def chatbot():\n",
    "    print(\"관리용 에이전트 챗봇입니다. '종료'라고 입력하면 대화가 끝납니다.\")\n",
    "    while True:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() == \"종료\":\n",
    "            print(\"대화를 종료합니다.\")\n",
    "            break\n",
    "        output = manage_agents(user_input)\n",
    "        print(\"Bot:\", output)\n",
    "\n",
    "# 챗봇 실행\n",
    "chatbot()\n"
   ],
   "id": "d959f6d86dcb765"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
